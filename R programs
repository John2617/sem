# ------------------- 1. Descriptive Statistics on iris -------------------
data <- iris

summary_stats <- summary(data)
mean_values <- sapply(data[, 1:4], mean)
median_values <- sapply(data[, 1:4], median)
variance_values <- sapply(data[, 1:4], var)
sd_values <- sapply(data[, 1:4], sd)

cat("Summary Statistics:\n")
print(summary_stats)
cat("\nMean Values:\n")
print(mean_values)
cat("\nMedian Values:\n")
print(median_values)
cat("\nVariance Values:\n")
print(variance_values)
cat("\nStandard Deviation Values:\n")
print(sd_values)


# ------------------- 2. One-Sample t-test -------------------
set.seed(123)
sample_data <- rnorm(20, mean = 10, sd = 2)
hypothesized_mean <- 10
alpha <- 0.05

ttest_res <- t.test(sample_data, mu = hypothesized_mean)

cat("\nOne sample t-test Result\n")
print(ttest_res)
cat("Mean of sample:", mean(sample_data), "\n")
cat("Hypothesized mean:", hypothesized_mean, "\n")
cat("T-statistic:", ttest_res$statistic, "\n")
cat("P-value:", ttest_res$p.value, "\n")

if (ttest_res$p.value < alpha) {
  cat("Conclusion: Reject null hypothesis\n")
} else {
  cat("Conclusion: Accept null hypothesis\n")
}


# ------------------- 3. Two-Sample t-test -------------------
group1 <- c(13.3, 6.0, 20.0, 8.0, 14.0, 19.0, 0.25, 0.0, 16.0, 24.0, 15.0, 1.0, 15.0, 18.0, 25.0, 16.0, 24.0)
group2 <- c(22.0, 16.0, 21.7, 21.0, 30.0, 26.0, 19.0, 23.9, 28.0, 23.0)

t_test_result <- t.test(group1, group2, var.equal = TRUE)

cat("\nStandard Two Sample t-test result for Equal Variance:\n")
print(t_test_result)
cat("p-value:", t_test_result$p.value, "\n")

if (t_test_result$p.value < alpha) {
  cat("Conclusion: Reject the Null hypothesis\n")
} else {
  cat("Conclusion: Fail to reject Null hypothesis\n")
}


# ------------------- 4. Chi-Square Test -------------------
alpha <- 0.05
data_matrix <- matrix(c(40, 30, 30, 50), nrow = 2)
rownames(data_matrix) <- c("Male", "Female")
colnames(data_matrix) <- c("Bev A", "Bev B")

cat("\nContingency Table:\n")
print(data_matrix)

result <- chisq.test(data_matrix)

cat("\nChi-Square Test Result:\n")
print(result)

df <- (nrow(data_matrix) - 1) * (ncol(data_matrix) - 1)
critical_value <- qchisq(1 - alpha, df)

cat("\nCritical Value (", alpha, "):", critical_value, "\n")

if (result$statistic > critical_value) {
  cat("\nReject the null hypothesis. There is a significant association.\n")
} else {
  cat("\nFail to reject the null hypothesis. No significant association.\n")
}


# ------------------- 5. ANOVA and Tukey's Test -------------------
method_A <- c(80, 85, 88, 92, 95)
method_B <- c(78, 75, 82, 87, 90)
method_C <- c(70, 72, 75, 80, 85)

data <- data.frame(
  method = factor(rep(c("A", "B", "C"), each = 5)),
  score = c(method_A, method_B, method_C)
)

anova_result <- aov(score ~ method, data = data)
summary(anova_result)

tukey_result <- TukeyHSD(anova_result)
cat("\nTukey's HSD Test:\n")
print(tukey_result)


# ------------------- 6. Non-Parametric Tests -------------------
library(stats)

group1 <- c(12, 14, 16, 18, 20)
group2 <- c(11, 13, 15, 17, 19)

sign_test <- binom.test(sum(group1 > group2), length(group1), p = 0.5, alternative = "greater")
cat("\nSign Test:\n")
print(sign_test)

signed_rank_test <- wilcox.test(group1, group2, paired = TRUE, exact = FALSE)
cat("\nSigned Rank Test:\n")
print(signed_rank_test)

mw_w_test <- wilcox.test(group1, group2)
cat("\nMann-Whitney-Wilcoxon Test:\n")
print(mw_w_test)


# ------------------- 8. Simple Linear Regression -------------------
car_age <- c(4, 4, 5, 5, 7, 7, 8, 9, 10, 11, 12)
price <- c(6300, 5800, 5700, 4500, 4500, 4200, 4200, 3100, 2100, 2500, 2200)

data <- data.frame(x = car_age, y = price)
linear_model <- lm(y ~ x, data = data)

cat("\nLinear Regression Summary:\n")
print(summary(linear_model))

plot(data$x, data$y, main = "Simple Linear Regression", xlab = "Car Age", ylab = "Price")
abline(linear_model, col = "red")

new_car_age <- c(6, 8, 10)
new_data <- data.frame(x = new_car_age)
predictions <- predict(linear_model, newdata = new_data)

cat("Predictions for new car ages:", predictions, "\n")

plot(data$x, data$y, main = "Regression with Predictions", xlab = "Car Age", ylab = "Price")
abline(linear_model, col = "red")
points(new_data$x, predictions, col = "blue", pch = 16)


# ------------------- 9. Residual Analysis -------------------
library(ggplot2)

x <- c(1, 2, 3, 4, 5)
y <- c(2, 5, 3, 8, 7)
model <- lm(y ~ x)
residuals <- resid(model)

ggplot(data.frame(Fitted = fitted(model), Residuals = residuals), aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted", x = "Fitted Values", y = "Residuals")

shapiro_test <- shapiro.test(residuals)
print(shapiro_test)

qqnorm(residuals)
qqline(residuals)
